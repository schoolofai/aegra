"""Thread endpoints for Agent Protocol"""
from uuid import uuid4
from datetime import datetime
from typing import List, Optional, Dict, Any
import json
import logging

from fastapi import APIRouter, HTTPException, Depends, Query, Body
from sqlalchemy import select
from sqlalchemy.ext.asyncio import AsyncSession

from ..models import Thread, ThreadCreate, ThreadList, ThreadSearchRequest, ThreadSearchResponse, ThreadState, ThreadHistoryRequest, User, ThreadCheckpoint
from ..core.auth_deps import get_current_user
from ..core.orm import Thread as ThreadORM, get_session
from ..core.database import db_manager

# TODO: adopt structured logging across all modules; replace print() and bare exceptions in:
# - agent_server/api/*.py
# - agent_server/services/*.py
# - agent_server/core/*.py
# - agent_server/models/*.py (where applicable)
# Use logging.getLogger(__name__) and appropriate levels (debug/info/warning/error).

router = APIRouter()
logger = logging.getLogger(__name__)


# In-memory storage removed; using database via ORM


@router.post("/threads", response_model=Thread)
async def create_thread(
    request: ThreadCreate,
    user: User = Depends(get_current_user),
    session: AsyncSession = Depends(get_session)
):
    """Create a new conversation thread"""
    
    thread_id = str(uuid4())

    # Build metadata with required fields
    metadata = request.metadata or {}
    metadata.update({
        "owner": user.identity,
        "assistantId": None,  # Will be set when first run is created
        "graphId": None,       # Will be set when first run is created  
        "threadName": "",      # User can update this later
    })
    
    thread_orm = ThreadORM(
        thread_id=thread_id,
        status="idle",
        metadata_json=metadata,
        user_id=user.identity,
    )
    # SQLAlchemy AsyncSession.add is sync; do not await
    session.add(thread_orm)
    await session.commit()
    # In tests, session.refresh may be a no-op; guard access to columns accordingly
    try:
        await session.refresh(thread_orm)
    except Exception:
        pass

    # TODO: initialize LangGraph checkpoint with initial_state if provided

    # Build a safe dict for Pydantic Thread validation, coercing MagicMocks to plain types
    def _coerce_str(val: Any, default: str) -> str:
        try:
            s = str(val)
            # MagicMock string often contains "MagicMock"; if so, fall back to default
            return default if "MagicMock" in s else s
        except Exception:
            return default

    def _coerce_dict(val: Any, default: Dict[str, Any]) -> Dict[str, Any]:
        if isinstance(val, dict):
            return val
        # Some mocks might pretend to be mapping; try to convert safely
        try:
            if hasattr(val, "items"):
                return dict(val.items())  # type: ignore[attr-defined]
        except Exception:
            pass
        return default

    coerced_thread_id = _coerce_str(getattr(thread_orm, "thread_id", thread_id), thread_id)
    coerced_status = _coerce_str(getattr(thread_orm, "status", "idle"), "idle")
    coerced_user_id = _coerce_str(getattr(thread_orm, "user_id", user.identity), user.identity)
    coerced_metadata = _coerce_dict(getattr(thread_orm, "metadata_json", metadata), metadata)
    coerced_created_at = getattr(thread_orm, "created_at", None)
    if not isinstance(coerced_created_at, datetime):
        coerced_created_at = datetime.utcnow()

    thread_dict: Dict[str, Any] = {
        "thread_id": coerced_thread_id,
        "status": coerced_status,
        "metadata": coerced_metadata,
        "user_id": coerced_user_id,
        "created_at": coerced_created_at,
    }

    return Thread.model_validate(thread_dict)


@router.get("/threads", response_model=ThreadList)
async def list_threads(
    user: User = Depends(get_current_user),
    session: AsyncSession = Depends(get_session)
):
    """List user's threads"""
    stmt = select(ThreadORM).where(ThreadORM.user_id == user.identity)
    result = await session.scalars(stmt)
    rows = result.all()
    user_threads = [
        Thread.model_validate({
            **{c.name: getattr(t, c.name) for c in t.__table__.columns},
            "metadata": t.metadata_json,
        })
        for t in rows
    ]
    return ThreadList(threads=user_threads, total=len(user_threads))


@router.get("/threads/{thread_id}", response_model=Thread)
async def get_thread(
    thread_id: str,
    user: User = Depends(get_current_user),
    session: AsyncSession = Depends(get_session)
):
    """Get thread by ID"""
    stmt = select(ThreadORM).where(ThreadORM.thread_id == thread_id, ThreadORM.user_id == user.identity)
    thread = await session.scalar(stmt)
    if not thread:
        raise HTTPException(404, f"Thread '{thread_id}' not found")

    return Thread.model_validate({
        **{c.name: getattr(thread, c.name) for c in thread.__table__.columns},
        "metadata": thread.metadata_json,
    })

@router.post("/threads/{thread_id}/history", response_model=List[ThreadState])
async def get_thread_history_post(
    thread_id: str,
    request: ThreadHistoryRequest,
    user: User = Depends(get_current_user),
    session: AsyncSession = Depends(get_session)
):
    """Get thread checkpoint history (POST method - for SDK compatibility)"""

    try:
        # Validate and coerce inputs
        limit = request.limit or 10
        if not isinstance(limit, int) or limit < 1 or limit > 1000:
            raise HTTPException(422, "Invalid limit; must be an integer between 1 and 1000")

        before = request.before
        if before is not None and not isinstance(before, str):
            raise HTTPException(422, "Invalid 'before' parameter; must be a string checkpoint identifier")

        metadata = request.metadata
        if metadata is not None and not isinstance(metadata, dict):
            raise HTTPException(422, "Invalid 'metadata' parameter; must be an object")

        checkpoint = request.checkpoint or {}
        if not isinstance(checkpoint, dict):
            raise HTTPException(422, "Invalid 'checkpoint' parameter; must be an object")

        # Optional flags
        subgraphs = bool(request.subgraphs) if request.subgraphs is not None else False
        checkpoint_ns = request.checkpoint_ns
        if checkpoint_ns is not None and not isinstance(checkpoint_ns, str):
            raise HTTPException(422, "Invalid 'checkpoint_ns'; must be a string")

        logger.debug(f"history POST: thread_id={thread_id} limit={limit} before={before} subgraphs={subgraphs} checkpoint_ns={checkpoint_ns}")

        # Verify the thread exists and belongs to the user
        stmt = select(ThreadORM).where(
            ThreadORM.thread_id == thread_id, ThreadORM.user_id == user.identity
        )
        thread = await session.scalar(stmt)
        if not thread:
            raise HTTPException(404, f"Thread '{thread_id}' not found")

        # Extract graph_id from thread metadata
        thread_metadata = thread.metadata_json or {}
        graph_id = thread_metadata.get("graphId")
        if not graph_id:
            # Return empty history if no graph is associated yet
            logger.info(f"history POST: no graph_id set for thread {thread_id}")
            return []

        # Get compiled graph
        from ..services.langgraph_service import get_langgraph_service, create_thread_config
        langgraph_service = get_langgraph_service()
        try:
            agent = await langgraph_service.get_graph(graph_id)
        except Exception as e:
            logger.exception("Failed to load graph '%s' for history", graph_id)
            raise HTTPException(500, f"Failed to load graph '{graph_id}': {str(e)}")

        # Build config with user context and thread_id
        config: Dict[str, Any] = create_thread_config(thread_id, user, {})
        # Merge checkpoint and namespace if provided
        if checkpoint:
            cfg_cp = checkpoint.copy()
            if checkpoint_ns is not None:
                cfg_cp.setdefault("checkpoint_ns", checkpoint_ns)
            config["configurable"].update(cfg_cp)
        elif checkpoint_ns is not None:
            config["configurable"]["checkpoint_ns"] = checkpoint_ns

        # Fetch state history
        state_snapshots = []
        kwargs = {
            "limit": limit,
            "before": before,
        }
        # The runtime may expect metadata filter under "filter" or "metadata"; try "metadata"
        if metadata is not None:
            kwargs["metadata"] = metadata  # type: ignore[index]

        # Some LangGraph versions support subgraphs flag; pass if available
        try:
            async for snapshot in agent.aget_state_history(config, subgraphs=subgraphs, **kwargs):
                state_snapshots.append(snapshot)
        except TypeError:
            # Fallback if subgraphs not supported in this version
            async for snapshot in agent.aget_state_history(config, **kwargs):
                state_snapshots.append(snapshot)

        # Map to ThreadState
        thread_states: List[ThreadState] = []
        for snapshot in state_snapshots:
            snap_config = getattr(snapshot, "config", {}) or {}
            parent_config = getattr(snapshot, "parent_config", {}) or {}
            checkpoint_id = None
            parent_checkpoint_id = None
            if isinstance(snap_config, dict):
                checkpoint_id = (snap_config.get("configurable") or {}).get("checkpoint_id")
            if isinstance(parent_config, dict):
                parent_checkpoint_id = (parent_config.get("configurable") or {}).get("checkpoint_id")

            created_at = getattr(snapshot, "created_at", None)

            current_checkpoint = ThreadCheckpoint(
                checkpoint_id=checkpoint_id,
                thread_id=thread_id,
                checkpoint_ns=(snap_config.get("configurable") or {}).get("checkpoint_ns", "") if isinstance(snap_config, dict) else "",
            )
            parent_checkpoint = None
            if parent_checkpoint_id:
                parent_checkpoint = ThreadCheckpoint(
                    checkpoint_id=parent_checkpoint_id,
                    thread_id=thread_id,
                    checkpoint_ns=(parent_config.get("configurable") or {}).get("checkpoint_ns", "") if isinstance(parent_config, dict) else "",
                )

            thread_state = ThreadState(
                values=getattr(snapshot, "values", {}),
                next=getattr(snapshot, "next", []) or [],
                tasks=[],  # TODO: serialize tasks if required
                metadata=getattr(snapshot, "metadata", {}) or {},
                created_at=created_at,
                checkpoint=current_checkpoint,
                parent_checkpoint=parent_checkpoint,
                checkpoint_id=checkpoint_id,
                parent_checkpoint_id=parent_checkpoint_id,
            )
            thread_states.append(thread_state)

        return thread_states

    except HTTPException:
        raise
    except Exception as e:
        logger.exception("Error in history POST for thread %s", thread_id)
        # Return empty list for clearly absent histories if backend signals not found-like cases
        msg = str(e).lower()
        if "not found" in msg or "no checkpoint" in msg:
            return []
        raise HTTPException(500, f"Error retrieving thread history: {str(e)}")


@router.get("/threads/{thread_id}/history", response_model=List[ThreadState])
async def get_thread_history_get(
    thread_id: str,
    limit: int = Query(10, ge=1, le=1000, description="Number of states to return"),
    before: Optional[str] = Query(None, description="Return states before this checkpoint ID"),
    subgraphs: Optional[bool] = Query(False, description="Include states from subgraphs"),
    checkpoint_ns: Optional[str] = Query(None, description="Checkpoint namespace"),
    # Optional metadata filter for parity with POST (use JSON string to avoid FastAPI typing assertion on dict in query)
    metadata: Optional[str] = Query(None, description="JSON-encoded metadata filter"),
    user: User = Depends(get_current_user),
    session: AsyncSession = Depends(get_session),
):
    """Get thread checkpoint history (GET method - SDK compatibility)"""
    # Reuse POST logic by constructing a ThreadHistoryRequest-like object
    # Parse metadata JSON string if provided
    parsed_metadata: Optional[Dict[str, Any]] = None
    if metadata:
        try:
            parsed_metadata = json.loads(metadata)
            if not isinstance(parsed_metadata, dict):
                raise ValueError("metadata must be a JSON object")
        except Exception as e:
            raise HTTPException(422, f"Invalid metadata query param: {e}")
    req = ThreadHistoryRequest(
        limit=limit,
        before=before,
        metadata=parsed_metadata,
        checkpoint=None,
        subgraphs=subgraphs,
        checkpoint_ns=checkpoint_ns,
    )
    return await get_thread_history_post(thread_id, req, user, session)


@router.delete("/threads/{thread_id}")
async def delete_thread(
    thread_id: str,
    user: User = Depends(get_current_user),
    session: AsyncSession = Depends(get_session)
):
    """Delete thread by ID"""
    stmt = select(ThreadORM).where(ThreadORM.thread_id == thread_id, ThreadORM.user_id == user.identity)
    thread = await session.scalar(stmt)
    if not thread:
        raise HTTPException(404, f"Thread '{thread_id}' not found")

    await session.delete(thread)
    await session.commit()
    return {"status": "deleted"}


@router.post("/threads/search", response_model=List[Thread])
async def search_threads(
    request: ThreadSearchRequest,
    user: User = Depends(get_current_user),
    session: AsyncSession = Depends(get_session)
):
    """Search threads with filters"""
    
    stmt = select(ThreadORM).where(ThreadORM.user_id == user.identity)

    if request.status:
        stmt = stmt.where(ThreadORM.status == request.status)

    if request.metadata:
        # For each key/value, filter JSONB field
        for key, value in request.metadata.items():
            stmt = stmt.where(ThreadORM.metadata_json[key].as_string() == str(value))

    # Count total first
    _count_result = await session.scalars(stmt)
    total = len(_count_result.all())

    offset = request.offset or 0
    limit = request.limit or 20
    stmt = stmt.offset(offset).limit(limit)

    result = await session.scalars(stmt)
    rows = result.all()
    threads_models = [
        Thread.model_validate({
            **{c.name: getattr(t, c.name) for c in t.__table__.columns},
            "metadata": t.metadata_json,
        })
        for t in rows
    ]

    # Return array of threads for client/vendor parity
    return threads_models
